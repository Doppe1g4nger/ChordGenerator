{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import music21\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input a single part musicXML file to predict the chord progression for: ../../data/test_data/test_inputs/Poster_Melody.musicxml\n"
     ]
    }
   ],
   "source": [
    "file_to_predict = input(\"Input a single part musicXML file to predict the chord progression for: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input the file path of the model to use for chord prediction: ../../data/models/model10.pt\n"
     ]
    }
   ],
   "source": [
    "model_fp = input(\"Input the file path of the model to use for chord prediction: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input the name of the file to save the predicted multipart piece to: ../../data/test_data/test_outputs/Poster_MelodyWC3.musicxml\n"
     ]
    }
   ],
   "source": [
    "prediction_file_name = input(\"Input the name of the file to save the predicted multipart piece to: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_start_bit = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0.0} <music21.instrument.Instrument 'P1: Melody: Piano'>\n",
      "{0.0} <music21.stream.Measure 1 offset=0.0>\n",
      "    {0.0} <music21.layout.SystemLayout>\n",
      "    {0.0} <music21.clef.TrebleClef>\n",
      "    {0.0} <music21.key.KeySignature of no sharps or flats>\n",
      "    {0.0} <music21.meter.TimeSignature 4/4>\n",
      "    {0.0} <music21.note.Rest rest>\n",
      "    {1.0} <music21.note.Note E>\n",
      "    {1.5} <music21.note.Note G>\n",
      "    {2.0} <music21.note.Note A>\n",
      "    {2.5} <music21.note.Note G>\n",
      "    {3.0} <music21.note.Note E>\n",
      "    {3.5} <music21.note.Note C>\n",
      "{4.0} <music21.stream.Measure 2 offset=4.0>\n",
      "    {0.0} <music21.note.Note E->\n",
      "    {0.5} <music21.note.Note D>\n",
      "    {1.5} <music21.note.Note D>\n",
      "    {3.5} <music21.note.Note C>\n",
      "{8.0} <music21.stream.Measure 3 offset=8.0>\n",
      "    {0.0} <music21.note.Note A>\n",
      "    {0.5} <music21.note.Note C>\n",
      "    {1.5} <music21.note.Note C>\n",
      "    {3.0} <music21.note.Note A>\n",
      "    {3.5} <music21.note.Note G>\n",
      "{12.0} <music21.stream.Measure 4 offset=12.0>\n",
      "    {0.0} <music21.note.Note E>\n",
      "{16.0} <music21.stream.Measure 5 offset=16.0>\n",
      "    {0.0} <music21.note.Rest rest>\n",
      "    {1.0} <music21.note.Note E>\n",
      "    {1.5} <music21.note.Note G>\n",
      "    {2.0} <music21.note.Note A>\n",
      "    {2.5} <music21.note.Note C>\n",
      "    {3.0} <music21.note.Note E->\n",
      "    {3.5} <music21.note.Note D>\n",
      "{20.0} <music21.stream.Measure 6 offset=20.0>\n",
      "    {0.0} <music21.note.Note D>\n",
      "    {0.5} <music21.note.Note C>\n",
      "    {1.0} <music21.note.Note A>\n",
      "    {1.5} <music21.note.Note C>\n",
      "    {3.5} <music21.note.Note G>\n",
      "{24.0} <music21.stream.Measure 7 offset=24.0>\n",
      "    {0.0} <music21.layout.SystemLayout>\n",
      "    {0.0} <music21.note.Note B->\n",
      "    {0.5} <music21.note.Note A>\n",
      "    {1.0} <music21.note.Note G>\n",
      "    {1.5} <music21.note.Note A>\n",
      "    {2.0} <music21.note.Note E->\n",
      "    {2.5} <music21.note.Note D>\n",
      "    {3.0} <music21.note.Rest rest>\n",
      "{28.0} <music21.stream.Measure 8 offset=28.0>\n",
      "    {0.0} <music21.note.Note C>\n",
      "    {4.0} <music21.bar.Barline type=final>\n"
     ]
    }
   ],
   "source": [
    "bins_per_measure = 16\n",
    "\n",
    "score = music21.converter.parse(file_to_predict)\n",
    "\n",
    "step_length = 4 / bins_per_measure\n",
    "\n",
    "melody = score.parts[0]\n",
    "\n",
    "melody.show(\"text\")\n",
    "\n",
    "melody_measures = melody.getElementsByClass(music21.stream.Measure)\n",
    "\n",
    "test_data = []\n",
    "for i, mel_measure in enumerate(melody_measures):\n",
    "    test_measure = []\n",
    "    if mel_measure.timeSignature is not None:\n",
    "        step_length = (mel_measure.timeSignature.numerator / mel_measure.timeSignature.denominator\n",
    "                       * 4 / bins_per_measure)\n",
    "    melody_elements = [item for item in mel_measure.notesAndRests]\n",
    "    melody_index = 0\n",
    "\n",
    "    melody_quintet = []\n",
    "    for j in range(bins_per_measure):\n",
    "        offset_timestep = j * step_length\n",
    "\n",
    "        if (melody_elements[melody_index] is not melody_elements[-1] \n",
    "            and melody_elements[melody_index + 1].offset <= offset_timestep):\n",
    "            melody_index += 1\n",
    "\n",
    "        melody_item = melody_elements[melody_index]\n",
    "        \n",
    "        item_index = melody_item.pitch.pitchClass if melody_item.name != \"rest\" else 12\n",
    "        item_vector = [1 if k == item_index else 0 for k in range(13)]\n",
    "        if use_start_bit:\n",
    "            item_vector.append(1 if i == 0 else 0)\n",
    "            \n",
    "        melody_quintet += item_vector\n",
    "\n",
    "        if j % 4 == 3:\n",
    "            test_data.append(melody_quintet)\n",
    "            melody_quintet = []\n",
    "    \n",
    "melody_tensor = torch.tensor(test_data, dtype=torch.float, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "torch.Size([32, 52])\n"
     ]
    }
   ],
   "source": [
    "print(melody_tensor)\n",
    "print(melody_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class LSTMGenerator(nn.Module):\n",
    "    \n",
    "#     def __init__(self):\n",
    "#         super(LSTMGenerator, self).__init__()\n",
    "#         self.embedding = nn.Embedding(13, 100)\n",
    "#         self.lstm = nn.LSTM(input_size=100, hidden_size=256, num_layers=2, batch_first=True)\n",
    "#         self.fc1 = nn.Linear(256, 12)\n",
    "        \n",
    "#     def forward(self, x, hidden_in):\n",
    "#         x = self.embedding(x)\n",
    "#         x, h_out = self.lstm(x, hidden_in)\n",
    "#         x = self.fc1(x)\n",
    "#         return x, h_out\n",
    "\n",
    "# model = LSTMGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class LSTMGenerator_v2(nn.Module):\n",
    "    \n",
    "#     def __init__(self):\n",
    "#         super(LSTMGenerator_v2, self).__init__()\n",
    "#         self.lstm = nn.LSTM(input_size=13, \n",
    "#                             hidden_size=256, \n",
    "#                             num_layers=2, \n",
    "#                             batch_first=True, \n",
    "#                             bidirectional=True, \n",
    "#                             dropout=0.2)\n",
    "#         self.fc1 = nn.Linear(512, 256)\n",
    "#         self.fc2 = nn.Linear(256, 12)\n",
    "        \n",
    "#     def forward(self, x, hidden_in):\n",
    "#         x, h_out = self.lstm(x, hidden_in)\n",
    "#         x = self.fc1(x)\n",
    "#         x = F.relu(x)\n",
    "#         x = self.fc2(x)\n",
    "        \n",
    "#         return x, h_out\n",
    "\n",
    "# model = LSTMGenerator_v2()\n",
    "\n",
    "# model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTMGenerator_v5(\n",
      "  (lstm): LSTM(52, 256, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n",
      "  (fc1): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=12, bias=True)\n",
      ")\n",
      "2346252\n"
     ]
    }
   ],
   "source": [
    "# Define recurrent prediction model\n",
    "class LSTMGenerator_v5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LSTMGenerator_v5, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size=52, \n",
    "                            hidden_size=256, \n",
    "                            num_layers=2, \n",
    "                            batch_first=True, \n",
    "                            bidirectional=True, \n",
    "                            dropout=0.2)\n",
    "        self.fc1 = nn.Linear(512, 256)\n",
    "        self.fc2 = nn.Linear(256, 12)\n",
    "        \n",
    "    def forward(self, x, hidden_in):\n",
    "        x, h_out = self.lstm(x, hidden_in)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x, h_out\n",
    "\n",
    "model = LSTMGenerator_v5()\n",
    "\n",
    "model.to(device)\n",
    "print(net)\n",
    "\n",
    "pytorch_total_params = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "print(pytorch_total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMGenerator_v5(\n",
       "  (lstm): LSTM(52, 256, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n",
       "  (fc1): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=12, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(model_fp))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "melody_tensor = melody_tensor.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 52])\n"
     ]
    }
   ],
   "source": [
    "print(melody_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0],\n",
       "        [1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0],\n",
       "        [0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0],\n",
       "        [1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0],\n",
       "        [1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1],\n",
       "        [0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1],\n",
       "        [1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1],\n",
       "        [1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0]], device='cuda:0',\n",
       "       dtype=torch.uint8)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_state = (torch.zeros(2 * 2, 1, 256, device=device),\n",
    "                torch.zeros(2 * 2, 1, 256, device=device))\n",
    "\n",
    "chord_tensor = (torch.sigmoid(model(melody_tensor, hidden_state)[0]) > 0.5)\n",
    "first_largest = -1\n",
    "second_largest = -1\n",
    "third_largest = -1\n",
    "chord_tensor.squeeze_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0.0} <music21.instrument.Piano 'Piano'>\n",
      "{0.0} <music21.stream.Measure 0 offset=0.0>\n",
      "    {0.0} <music21.meter.TimeSignature 4/4>\n",
      "    {0.0} <music21.chord.Chord C E G>\n",
      "    {2.0} <music21.chord.Chord C E G B->\n",
      "    {3.0} <music21.chord.Chord C E G>\n",
      "{4.0} <music21.stream.Measure 0 offset=4.0>\n",
      "    {0.0} <music21.meter.TimeSignature 4/4>\n",
      "    {0.0} <music21.chord.Chord C E G>\n",
      "    {1.0} <music21.chord.Chord D G B->\n",
      "    {3.0} <music21.chord.Chord C F A>\n",
      "{8.0} <music21.stream.Measure 0 offset=8.0>\n",
      "    {0.0} <music21.meter.TimeSignature 4/4>\n",
      "    {0.0} <music21.chord.Chord C F A>\n",
      "    {3.0} <music21.chord.Chord C E G>\n",
      "{12.0} <music21.stream.Measure 0 offset=12.0>\n",
      "    {0.0} <music21.meter.TimeSignature 4/4>\n",
      "    {0.0} <music21.chord.Chord C E G>\n",
      "{16.0} <music21.stream.Measure 0 offset=16.0>\n",
      "    {0.0} <music21.meter.TimeSignature 4/4>\n",
      "    {0.0} <music21.chord.Chord C E G>\n",
      "    {3.0} <music21.chord.Chord C F A>\n",
      "{20.0} <music21.stream.Measure 0 offset=20.0>\n",
      "    {0.0} <music21.meter.TimeSignature 4/4>\n",
      "    {0.0} <music21.chord.Chord C F A>\n",
      "{24.0} <music21.stream.Measure 0 offset=24.0>\n",
      "    {0.0} <music21.meter.TimeSignature 4/4>\n",
      "    {0.0} <music21.chord.Chord D A B>\n",
      "    {1.0} <music21.chord.Chord D G A B>\n",
      "    {2.0} <music21.chord.Chord C F A B>\n",
      "    {3.0} <music21.chord.Chord C F A>\n",
      "{28.0} <music21.stream.Measure 0 offset=28.0>\n",
      "    {0.0} <music21.meter.TimeSignature 4/4>\n",
      "    {0.0} <music21.chord.Chord C F A>\n",
      "    {1.0} <music21.chord.Chord C G>\n",
      "    {2.0} <music21.chord.Chord C E G>\n"
     ]
    }
   ],
   "source": [
    "new_part = music21.stream.Part()\n",
    "new_part.insert(0, music21.instrument.Piano())\n",
    "\n",
    "time_sig = music21.meter.TimeSignature(\"4/4\")\n",
    "\n",
    "for measure in torch.chunk(chord_tensor, int(chord_tensor.shape[0] / 4)):\n",
    "    new_measure = music21.stream.Measure()\n",
    "    new_measure.insert(0, time_sig)\n",
    "    pitch_classes = [[i for i, val in enumerate(chord_vector) if val == 1] for chord_vector in measure]\n",
    "    pitch_class_to_quarterlength = [[pitch_classes[0], (4 * 4 / bins_per_measure)]]\n",
    "    for i, p_class in enumerate(pitch_classes[1:], 1):\n",
    "        if p_class == pitch_classes[i - 1]:\n",
    "            pitch_class_to_quarterlength[-1][1] += (4 * 4 / bins_per_measure)\n",
    "        else:\n",
    "            pitch_class_to_quarterlength.append([p_class, (4 * 4 / bins_per_measure)])\n",
    "            \n",
    "    for pitch_class_list, quarterlength in pitch_class_to_quarterlength:\n",
    "        if pitch_class_list != []:\n",
    "            new_measure.append(music21.chord.Chord(pitch_class_list, quarterLength=quarterlength))\n",
    "        else:\n",
    "            new_measure.append(music21.note.Rest(quarterLength=quarterlength))\n",
    "            \n",
    "    new_part.append(new_measure)\n",
    "\n",
    "new_part.show(\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "score.insert(0, new_part)\n",
    "\n",
    "gex = music21.musicxml.m21ToXml.GeneralObjectExporter(score)\n",
    "    \n",
    "out = gex.parse()\n",
    "musicxml = out.decode('utf-8').strip()\n",
    "    \n",
    "with open(prediction_file_name, \"w\") as outfile:\n",
    "    outfile.write(musicxml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (anaconda3 w pytorch)",
   "language": "python",
   "name": "mykernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
